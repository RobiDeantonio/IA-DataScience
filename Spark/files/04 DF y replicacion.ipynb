{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes y replicación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos un contexto de Spark y otro de SQL\n",
    "\n",
    "Nota: Cargo desde el inicio todos los métodos/modulos que se usarán a lo largo del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "import pyspark.sql \n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType,FloatType\n",
    "from pyspark.sql.types import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/16 20:46:53 WARN Utils: Your hostname, localhost resolves to a loopback address: 127.0.0.1; using 172.18.0.2 instead (on interface eth0)\n",
      "21/12/16 20:46:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/16 20:46:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/usr/local/spark/python/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "spark = SparkContext(master=\"local\", appName=\"DF y replicación\")\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DF y replicación</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=DF y replicación>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para eliminar encabezados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropFirstRow(index,iterator):\n",
    "     return iter(list(iterator)[1:]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del primer DataFrame\n",
    "\n",
    "Las tres cosas que debes recordar al crear un Dataframe desde un RDDs son:\n",
    "1. En caso de tener encabezado, eliminarlo\n",
    "2. Seleccionar y hacer explícita la seperación de las columnas. Si es necesario castear valores\n",
    "3. Crear el esquema a usarse con los tipos de datos de Spark\n",
    "\n",
    "Cambia el valor de la ruta para que apunte a la ruta donde tienes los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deportista_id,nombre,genero,edad,altura,peso,equipo_id\r\n",
      "1,A Dijiang,1,24,180,80,199\r\n",
      "2,A Lamusi,1,23,170,60,199\r\n",
      "3,Gunnar Nielsen Aaby,1,24,0,0,273\r\n",
      "4,Edgar Lindenau Aabye,1,34,0,0,278\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 data/deportista.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/\"\n",
    "\n",
    "deportistaOlimpicoRDD =  spark.textFile(path+\"deportista.csv\").map(lambda line : line.split(\",\"))\n",
    "deportistaOlimpico2RDD = spark.textFile(path+\"deportista2.csv\").map(lambda line : line.split(\",\"))\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.union(deportistaOlimpico2RDD)\n",
    "\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.mapPartitionsWithIndex(dropFirstRow)\n",
    "\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.map(lambda l : (\n",
    "int(l[0]),\n",
    "l[1],\n",
    "int(l[2]),\n",
    "int(l[3]),\n",
    "int(l[4]),\n",
    "float(l[5]),\n",
    "int(l[6])\n",
    "))\n",
    "\n",
    "schema = StructType([\n",
    "StructField(\"deportista_id\",IntegerType(),False)     ,\n",
    "StructField(\"nombre\",StringType(),False)        ,\n",
    "StructField(\"genero\",IntegerType(),False)        ,\n",
    "StructField(\"edad\",IntegerType(),True)      ,\n",
    "StructField(\"altura\",IntegerType(),True)        ,\n",
    "StructField(\"peso\",FloatType(),True)      ,\n",
    "StructField(\"equipo_id\",IntegerType(),True)     \n",
    "])\n",
    "\n",
    "deportistaOlimpicoDF = sqlContext.createDataFrame(deportistaOlimpicoRDD,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|            1|           A Dijiang|     1|  24|   180|80.0|      199|\n",
      "|            2|            A Lamusi|     1|  23|   170|60.0|      199|\n",
      "|            3| Gunnar Nielsen Aaby|     1|  24|     0| 0.0|      273|\n",
      "|            4|Edgar Lindenau Aabye|     1|  34|     0| 0.0|      278|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de DF desde archivo\n",
    "\n",
    "En el caso de la creación de un DF desde cero, solo debemos de indicar la estructura, nombre del archivo y opcionalmente si posee o no encabezado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte_id,deporte\r\n",
      "1,Basketball\r\n",
      "2,Judo\r\n",
      "3,Football\r\n",
      "4,Tug-Of-War\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 data/deporte.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportesOlimpicosRDDSchema = StructType(\n",
    "    [StructField(\"deporte_id\",IntegerType(),False),\n",
    "     StructField(\"deporte\",StringType(),False)\n",
    "    ])\n",
    "\n",
    "deportesDF = sqlContext.read.schema(deportesOlimpicosRDDSchema).option(\"header\",\"true\").csv(path+\"deporte.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|deporte_id|      deporte|\n",
      "+----------+-------------+\n",
      "|         1|   Basketball|\n",
      "|         2|         Judo|\n",
      "|         3|     Football|\n",
      "|         4|   Tug-Of-War|\n",
      "|         5|Speed Skating|\n",
      "+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportesDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reto\n",
    "\n",
    "Dar vida a todos los archivos como Dataframes.\n",
    "\n",
    "Se anexa una solución probable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte.csv\t deportistaError.csv  modelo_relacional.jpg\r\n",
      "deportista2.csv  evento.csv\t      paises.csv\r\n",
      "deportista.csv\t juegos.csv\t      resultados.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,equipo,sigla\r\n",
      "1,30. Februar,AUT\r\n",
      "2,A North American Team,MEX\r\n",
      "3,Acipactli,MEX\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 4 data/paises.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "paisesRDD = spark.textFile(path+\"paises.csv\").map(lambda line : line.split(\",\"))\n",
    "paisesRDD = paisesRDD.mapPartitionsWithIndex(dropFirstRow)\n",
    "\n",
    "paisesRDD = paisesRDD.map(lambda l : (\n",
    "int(l[0]),\n",
    "l[1],\n",
    "l[2]\n",
    "))\n",
    "\n",
    "schema = StructType([\n",
    "StructField(\"id\",IntegerType(),False),\n",
    "StructField(\"equipo\",StringType(),False),\n",
    "StructField(\"sigla\",StringType(),False)\n",
    "])\n",
    "\n",
    "paisesDF = sqlContext.createDataFrame(paisesRDD,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evento_id,evento,deporte_id\r\n",
      "1,Basketball Men's Basketball,1\r\n",
      "2,Judo Men's Extra-Lightweight,2\r\n",
      "3,Football Men's Football,3\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 4 data/evento.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventoSchema= StructType([\n",
    "    StructField(\"evento_id\",IntegerType(),False),\n",
    "    StructField(\"evento\",StringType(),False),\n",
    "    StructField(\"deporte_id\",IntegerType(),False)\n",
    "])\n",
    "\n",
    "deportesOlimpicosDF = sqlContext.read.schema(eventoSchema).option(\"header\",\"true\").csv(path+\"evento.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",nombre_juego,annio,temporada,ciudad\r\n",
      "1,1896 Verano,1896,Verano,Athina\r\n",
      "2,1900 Verano,1900,Verano,Paris\r\n",
      "3,1904 Verano,1904,Verano,St. Louis\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 4 data/juegos.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "juegoSchema = StructType([\n",
    "    StructField(\"juego_id\", IntegerType(),False),\n",
    "    StructField(\"nombre_juego\",StringType(),False),\n",
    "    StructField(\"annio\",StringType(),False),\n",
    "    StructField(\"temporada\",StringType(),False),\n",
    "    StructField(\"ciudad\",StringType(),False),\n",
    "])\n",
    "juegoDF = sqlContext.read.schema(juegoSchema).option(\"header\",\"true\").csv(path+\"juegos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado_id,medalla,deportista_id,juego_id,evento_id\r\n",
      "1,NA,1,39,1\r\n",
      "2,NA,2,49,2\r\n",
      "3,NA,3,7,3\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 4 data/resultados.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadoSchema = StructType([\n",
    "    StructField(\"resultado_id\",IntegerType(),False),\n",
    "    StructField(\"medalla\",StringType(),False),\n",
    "    StructField(\"deportista_id\",IntegerType(),False),\n",
    "    StructField(\"juego_id\",IntegerType(),False),\n",
    "    StructField(\"evento_id\",IntegerType(),False),\n",
    "])\n",
    "resultadoDF = sqlContext.read.schema(resultadoSchema).option(\"header\",\"true\").csv(path+\"resultados.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(deporte_id=1, deporte='Basketball'),\n",
       " Row(deporte_id=2, deporte='Judo'),\n",
       " Row(deporte_id=3, deporte='Football'),\n",
       " Row(deporte_id=4, deporte='Tug-Of-War'),\n",
       " Row(deporte_id=5, deporte='Speed Skating')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deportesDF.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(evento_id=1, evento=\"Basketball Men's Basketball\", deporte_id=1),\n",
       " Row(evento_id=2, evento=\"Judo Men's Extra-Lightweight\", deporte_id=2),\n",
       " Row(evento_id=3, evento=\"Football Men's Football\", deporte_id=3),\n",
       " Row(evento_id=4, evento=\"Tug-Of-War Men's Tug-Of-War\", deporte_id=4),\n",
       " Row(evento_id=5, evento=\"Speed Skating Women's 500 metres\", deporte_id=5)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deportesOlimpicosDF.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, equipo='30. Februar', sigla='AUT'),\n",
       " Row(id=2, equipo='A North American Team', sigla='MEX'),\n",
       " Row(id=3, equipo='Acipactli', sigla='MEX'),\n",
       " Row(id=4, equipo='Acturus', sigla='ARG'),\n",
       " Row(id=5, equipo='Afghanistan', sigla='AFG')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paisesDF.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/16 20:47:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , nombre_juego, annio, temporada, ciudad\n",
      " Schema: juego_id, nombre_juego, annio, temporada, ciudad\n",
      "Expected: juego_id but found: \n",
      "CSV file: file:///home/jovyan/work/data/juegos.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(juego_id=1, nombre_juego='1896 Verano', annio='1896', temporada='Verano', ciudad='Athina'),\n",
       " Row(juego_id=2, nombre_juego='1900 Verano', annio='1900', temporada='Verano', ciudad='Paris'),\n",
       " Row(juego_id=3, nombre_juego='1904 Verano', annio='1904', temporada='Verano', ciudad='St. Louis'),\n",
       " Row(juego_id=4, nombre_juego='1906 Verano', annio='1906', temporada='Verano', ciudad='Athina'),\n",
       " Row(juego_id=5, nombre_juego='1908 Verano', annio='1908', temporada='Verano', ciudad='London')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juegoDF.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(deportista_id=1, nombre='A Dijiang', genero=1, edad=24, altura=180, peso=80.0, equipo_id=199),\n",
       " Row(deportista_id=2, nombre='A Lamusi', genero=1, edad=23, altura=170, peso=60.0, equipo_id=199),\n",
       " Row(deportista_id=3, nombre='Gunnar Nielsen Aaby', genero=1, edad=24, altura=0, peso=0.0, equipo_id=273),\n",
       " Row(deportista_id=4, nombre='Edgar Lindenau Aabye', genero=1, edad=34, altura=0, peso=0.0, equipo_id=278),\n",
       " Row(deportista_id=5, nombre='Christine Jacoba Aaftink', genero=2, edad=21, altura=185, peso=82.0, equipo_id=705)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deportistaOlimpicoDF.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(resultado_id=1, medalla='NA', deportista_id=1, juego_id=39, evento_id=1),\n",
       " Row(resultado_id=2, medalla='NA', deportista_id=2, juego_id=49, evento_id=2),\n",
       " Row(resultado_id=3, medalla='NA', deportista_id=3, juego_id=7, evento_id=3),\n",
       " Row(resultado_id=4, medalla='Gold', deportista_id=4, juego_id=2, evento_id=4),\n",
       " Row(resultado_id=5, medalla='NA', deportista_id=5, juego_id=36, evento_id=5)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultadoDF.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión de esquema\n",
    "\n",
    "En ocasiones nosotros no creamos los Dataframes y la estrucutra es desconocida para nosotros. con ayuda del método 'printSchema' podemos conocer el esquema del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- deporte_id: integer (nullable = true)\n",
      " |-- deporte: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- deportista_id: integer (nullable = false)\n",
      " |-- nombre: string (nullable = false)\n",
      " |-- genero: integer (nullable = false)\n",
      " |-- edad: integer (nullable = true)\n",
      " |-- altura: integer (nullable = true)\n",
      " |-- peso: float (nullable = true)\n",
      " |-- equipo_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones de renombrado y eliminación\n",
    "\n",
    "Para renombrar una columna de un DF, podemos usar el método 'withColumnRenamed' o 'alias'.\n",
    "\n",
    "Para eliminar columnas, podemos usar el método 'drop' o simplemente selecionar las columnas que deseamos y sobreesciribr el DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoDF_2 = deportistaOlimpicoDF\n",
    "deportistaOlimpicoDF_2 = deportistaOlimpicoDF_2.withColumnRenamed(\"genero\",\"sexo\").drop(\"altura\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- deportista_id: integer (nullable = false)\n",
      " |-- nombre: string (nullable = false)\n",
      " |-- sexo: integer (nullable = false)\n",
      " |-- edad: integer (nullable = true)\n",
      " |-- peso: float (nullable = true)\n",
      " |-- equipo_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "deportistaOlimpicoDF_2 = deportistaOlimpicoDF_2.select(\"deportista_id\",\"nombre\",\n",
    "                            col(\"edad\").alias(\"edadAlJugar\"),\"equipo_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-----------+---------+\n",
      "|deportista_id|              nombre|edadAlJugar|equipo_id|\n",
      "+-------------+--------------------+-----------+---------+\n",
      "|            1|           A Dijiang|         24|      199|\n",
      "|            2|            A Lamusi|         23|      199|\n",
      "|            3| Gunnar Nielsen Aaby|         24|      273|\n",
      "|            4|Edgar Lindenau Aabye|         34|      278|\n",
      "|            5|Christine Jacoba ...|         21|      705|\n",
      "+-------------+--------------------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF_2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado de valores\n",
    "\n",
    "Como con el uso de RDDs, podemos usar el método 'filter' para selecionar subconjuntos.\n",
    "\n",
    "filter permite usar operaciones lógicas y de comparación como <,>,>=,!= , &,| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoDF_2 = deportistaOlimpicoDF_2.filter( (deportistaOlimpicoDF_2.edadAlJugar != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 12:>                                                         (0 + 1) / 2]\r",
      "\r",
      "[Stage 12:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-----------+---------+\n",
      "|deportista_id|              nombre|edadAlJugar|equipo_id|\n",
      "+-------------+--------------------+-----------+---------+\n",
      "|        71691|  Dimitrios Loundras|         10|      333|\n",
      "|        52070|        Etsuko Inada|         11|      514|\n",
      "|        40129|    Luigina Giavotti|         11|      507|\n",
      "|        37333|Carlos Bienvenido...|         11|      982|\n",
      "|        47618|Sonja Henie Toppi...|         11|      742|\n",
      "+-------------+--------------------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF_2.sort(\"edadAlJugar\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- deportista_id: integer (nullable = false)\n",
      " |-- nombre: string (nullable = false)\n",
      " |-- genero: integer (nullable = false)\n",
      " |-- edad: integer (nullable = true)\n",
      " |-- altura: integer (nullable = true)\n",
      " |-- peso: float (nullable = true)\n",
      " |-- equipo_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- resultado_id: integer (nullable = true)\n",
      " |-- medalla: string (nullable = true)\n",
      " |-- deportista_id: integer (nullable = true)\n",
      " |-- juego_id: integer (nullable = true)\n",
      " |-- evento_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultadoDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- juego_id: integer (nullable = true)\n",
      " |-- nombre_juego: string (nullable = true)\n",
      " |-- annio: string (nullable = true)\n",
      " |-- temporada: string (nullable = true)\n",
      " |-- ciudad: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "juegoDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- evento_id: integer (nullable = true)\n",
      " |-- evento: string (nullable = true)\n",
      " |-- deporte_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportesOlimpicosDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unión de DF\n",
    "\n",
    "Las operaciones conocidas como Join en SQL, tienen una impementación similar, ya que  el método 'join' recibe tres componentes:\n",
    "\n",
    "| Orden | Argumento | Descripción |\n",
    "|-------|--------|-----|\n",
    "|1|dataFrame|dataFrame con el que queremos realizar el cruce|\n",
    "|2|Cruze|Operación lógica a realizar para poder unir los Dataframes|\n",
    "|3|Tipo|El tipo de join a realizar: \"Left\", \"Right\",etc|\n",
    "\n",
    "No olvides que un join es una operación binaria. Por lo que si deseas unir mas DF, deberás realizar multiples joins\n",
    "\n",
    "Posterior a los joins realizados, debemos de realizar una operación select para indicar que valores queremos. \n",
    "\n",
    "En el caso de campos repetidos, podemos hacer explícito el dataframe de origen y para evitar confusón, utilizar alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/16 20:47:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , annio\n",
      " Schema: juego_id, annio\n",
      "Expected: juego_id but found: \n",
      "CSV file: file:///home/jovyan/work/data/juegos.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-------+------------+--------------------+\n",
      "|              nombre|Edad al jugar|medalla|Año de juego|Nombre de disciplina|\n",
      "+--------------------+-------------+-------+------------+--------------------+\n",
      "|           A Dijiang|           24|     NA|        1992|Basketball Men's ...|\n",
      "|            A Lamusi|           23|     NA|        2012|Judo Men's Extra-...|\n",
      "| Gunnar Nielsen Aaby|           24|     NA|        1920|Football Men's Fo...|\n",
      "|Edgar Lindenau Aabye|           34|   Gold|        1900|Tug-Of-War Men's ...|\n",
      "|Christine Jacoba ...|           21|     NA|        1994|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|           21|     NA|        1994|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|           21|     NA|        1992|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|           21|     NA|        1992|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|           21|     NA|        1988|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|           21|     NA|        1988|Speed Skating Wom...|\n",
      "|     Per Knut Aaland|           31|     NA|        1994|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|        1994|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|        1994|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|        1994|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|        1992|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|        1992|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|        1992|Cross Country Ski...|\n",
      "|     Per Knut Aaland|           31|     NA|        1992|Cross Country Ski...|\n",
      "|        John Aalberg|           31|     NA|        1994|Cross Country Ski...|\n",
      "|        John Aalberg|           31|     NA|        1994|Cross Country Ski...|\n",
      "+--------------------+-------------+-------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaOlimpicoDF.join(resultadoDF, deportistaOlimpicoDF.deportista_id == resultadoDF.deportista_id,\"left\") \\\n",
    "    .join(juegoDF,juegoDF.juego_id == resultadoDF.juego_id,\"left\") \\\n",
    "    .join(deportesOlimpicosDF, deportesOlimpicosDF.evento_id == resultadoDF.evento_id,\"left\") \\\n",
    "    .select(deportistaOlimpicoDF.nombre,col(\"edad\").alias(\"Edad al jugar\"),\n",
    "           \"medalla\",col(\"annio\").alias(\"Año de juego\"), \\\n",
    "           deportesOlimpicosDF.evento.alias(\"Nombre de disciplina\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma que una instrucción SQL posee una jerarquía para poder funcionar y retornar correctamente los valores que deseamos. Los DF estan reguidos por las mismas reglas, es decir la misma jerarquía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+\n",
      "|medalla|  equipo|sigla|\n",
      "+-------+--------+-----+\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Bronze|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "+-------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultadoDF.filter(resultadoDF.medalla != \"NA\") \\\n",
    "    .join(deportistaOlimpicoDF,deportistaOlimpicoDF.deportista_id == resultadoDF.deportista_id,\"left\") \\\n",
    "    .join(paisesDF,paisesDF.id == deportistaOlimpicoDF.equipo_id, \"left\") \\\n",
    "    .select(\"medalla\", \"equipo\",\"sigla\").sort( col(\"sigla\").desc() ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones escalares\n",
    "\n",
    "De la misma forma que SQL posee funciones para poder obtener estadísticas. DF hereda el mismo concepto apoyandose de los métodos 'groupBy', \"agg\" y los ya conocidos de sql \"count\",\"sum\",\"avg\" etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el ejercicio, buscaremos conocer cuantas medallas ha ganado un pais en cada juego olimpico.\n",
    "\n",
    "Primero realizamos la batería de joins que nos permitan identificar todos los valores que necesitamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "medallistaXAnio = deportistaOlimpicoDF \\\n",
    "        .join(resultadoDF, deportistaOlimpicoDF.deportista_id ==resultadoDF.deportista_id,\"left\") \\\n",
    "        .join(juegoDF, juegoDF.juego_id == resultadoDF.juego_id,\"left\") \\\n",
    "        .join(paisesDF,deportistaOlimpicoDF.equipo_id == paisesDF.id,\"left\") \\\n",
    "        .join(deportesOlimpicosDF, deportesOlimpicosDF.evento_id == resultadoDF.evento_id,\"left\") \\\n",
    "        .join(deportesDF,deportesOlimpicosDF.deporte_id == deportesDF.deporte_id,\"left\") \\\n",
    "        .select(\"sigla\",\n",
    "                \"annio\",\n",
    "                \"medalla\",\n",
    "                deportesOlimpicosDF.evento.alias(\"Nombre subdisciplina\"),\n",
    "                deportesDF.deporte.alias(\"Nombre disciplina\"),\n",
    "                deportistaOlimpicoDF.nombre,   \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/16 21:33:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , annio\n",
      " Schema: juego_id, annio\n",
      "Expected: juego_id but found: \n",
      "CSV file: file:///home/jovyan/work/data/juegos.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+--------------------+--------------------+--------------------+\n",
      "|sigla|annio|medalla|Nombre subdisciplina|   Nombre disciplina|              nombre|\n",
      "+-----+-----+-------+--------------------+--------------------+--------------------+\n",
      "|  CHN| 1992|     NA|Basketball Men's ...|          Basketball|           A Dijiang|\n",
      "|  CHN| 2012|     NA|Judo Men's Extra-...|                Judo|            A Lamusi|\n",
      "|  DEN| 1920|     NA|Football Men's Fo...|            Football| Gunnar Nielsen Aaby|\n",
      "|  SWE| 1900|   Gold|Tug-Of-War Men's ...|          Tug-Of-War|Edgar Lindenau Aabye|\n",
      "|  NED| 1994|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED| 1994|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED| 1992|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED| 1992|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED| 1988|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED| 1988|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  USA| 1994|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA| 1994|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA| 1994|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA| 1994|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA| 1992|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA| 1992|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA| 1992|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA| 1992|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA| 1994|     NA|Cross Country Ski...|Cross Country Skiing|        John Aalberg|\n",
      "|  USA| 1994|     NA|Cross Country Ski...|Cross Country Skiing|        John Aalberg|\n",
      "+-----+-----+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medallistaXAnio.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previo, identificamos el uso del método \"like\".\n",
    "\n",
    "El cual es util cuando no sabemos el nombre completo o correcto de una columna deseada. \n",
    "\n",
    "En este ejemplo, apartir de todos los juegos de Ski Aplino Femenino, obtenemos la competencias en las que participó el pais. Recuerda que la columna medalla aun posee valores NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/16 21:51:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , annio\n",
      " Schema: juego_id, annio\n",
      "Expected: juego_id but found: \n",
      "CSV file: file:///home/jovyan/work/data/juegos.csv\n",
      "[Stage 129:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n",
      "|sigla|annio|count|\n",
      "+-----+-----+-----+\n",
      "|  SUI| 1936|    2|\n",
      "|  NOR| 1936|    3|\n",
      "|  CAN| 1936|    4|\n",
      "|  NED| 1936|    1|\n",
      "|  LAT| 1936|    1|\n",
      "|  EST| 1936|    1|\n",
      "|  GBR| 1936|    4|\n",
      "|  GER| 1936|    4|\n",
      "|  TCH| 1936|    3|\n",
      "|  ITA| 1936|    4|\n",
      "|  AUT| 1936|    4|\n",
      "|  ESP| 1936|    2|\n",
      "|  USA| 1936|    4|\n",
      "|  FRA| 1948|   14|\n",
      "|  HUN| 1948|    3|\n",
      "|  ITA| 1948|    6|\n",
      "|  GBR| 1948|   12|\n",
      "|  AUT| 1948|   14|\n",
      "|  SUI| 1948|   14|\n",
      "|  SWE| 1948|    3|\n",
      "+-----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "medallistaXAnio.where( col(\"Nombre subdisciplina\").like(\"Alpine Skiing Wo%\")) \\\n",
    "    .groupBy(\"sigla\",\"annio\").count() \\\n",
    "    .sort(col(\"annio\").asc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso nos quedamos solo con medallas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/16 21:51:37 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , annio\n",
      " Schema: juego_id, annio\n",
      "Expected: juego_id but found: \n",
      "CSV file: file:///home/jovyan/work/data/juegos.csv\n",
      "[Stage 139:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------------------+-----+\n",
      "|Sigla|annio|Nombre subdisciplina|count|\n",
      "+-----+-----+--------------------+-----+\n",
      "|  USA| 1896|Athletics Men's D...|    1|\n",
      "|  USA| 1896|Athletics Men's 1...|    1|\n",
      "|  FRA| 1896|Cycling Men's 100...|    1|\n",
      "|  USA| 1896|Athletics Men's 4...|    2|\n",
      "|  GER| 1896|Gymnastics Men's ...|    2|\n",
      "|  FRA| 1896|Cycling Men's Sprint|    2|\n",
      "|  GER| 1896|Gymnastics Men's ...|   10|\n",
      "|  FRA| 1896|Cycling Men's 10,...|    2|\n",
      "|  AUS| 1896|Athletics Men's 1...|    1|\n",
      "|  GER| 1896|Athletics Men's 1...|    1|\n",
      "|  FRA| 1896|Fencing Men's Foi...|    2|\n",
      "|  GBR| 1896|Athletics Men's 4...|    1|\n",
      "|  GBR| 1896|Cycling Men's Roa...|    1|\n",
      "|  GRE| 1896|Cycling Men's 100...|    1|\n",
      "|  USA| 1896|Athletics Men's L...|    3|\n",
      "|  GRE| 1896|Shooting Men's Fr...|    2|\n",
      "|  GRE| 1896|Tennis Men's Singles|    2|\n",
      "|  GBR| 1896|Tennis Men's Singles|    1|\n",
      "|  USA| 1896|Athletics Men's H...|    3|\n",
      "|  HUN| 1896|Swimming Men's 10...|    1|\n",
      "+-----+-----+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "medallistaXAnio2 = medallistaXAnio.filter(medallistaXAnio.medalla != \"NA\") \\\n",
    "    .groupBy(\"Sigla\",\"annio\",\"Nombre subdisciplina\") \\\n",
    "    .count() \\\n",
    "    .sort(col(\"annio\").asc())\n",
    "medallistaXAnio2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forma recomendada para agrupar\n",
    "\n",
    "El método 'agg' es la forma recomendada para hacer agrupaciones ya que brinda la oportunidad de escalar la cantidad de operaciones escalares a realizar en un mismo DF.\n",
    "\n",
    "Es claro que si solo realizamos una operación de agrupación, el uso de 'agg' es excesivo, esta es la recomendación oficial de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/16 22:00:29 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , annio\n",
      " Schema: juego_id, annio\n",
      "Expected: juego_id but found: \n",
      "CSV file: file:///home/jovyan/work/data/juegos.csv\n",
      "[Stage 188:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----------------+------------------+\n",
      "|sigla|annio|Total de medallas| Medallas promedio|\n",
      "+-----+-----+-----------------+------------------+\n",
      "|  GRE| 1896|               48|1.6551724137931034|\n",
      "|  GER| 1896|               32|2.6666666666666665|\n",
      "|  USA| 1896|               20|1.6666666666666667|\n",
      "|  FRA| 1896|               11|             1.375|\n",
      "|  GBR| 1896|                9|             1.125|\n",
      "|  HUN| 1896|                6|               1.0|\n",
      "|  DEN| 1896|                6|               1.0|\n",
      "|  AUT| 1896|                5|               1.0|\n",
      "|  SUI| 1896|                3|               1.0|\n",
      "|  AUS| 1896|                3|               1.0|\n",
      "|  FRA| 1900|              250| 4.310344827586207|\n",
      "|  GBR| 1900|               90|3.4615384615384617|\n",
      "|  USA| 1900|               67| 2.310344827586207|\n",
      "|  GER| 1900|               45| 6.428571428571429|\n",
      "|  BEL| 1900|               45|            2.8125|\n",
      "|  NED| 1900|               26| 4.333333333333333|\n",
      "|  SUI| 1900|               21|               3.5|\n",
      "|  NOR| 1900|                9|               1.8|\n",
      "|  DEN| 1900|                7|               1.0|\n",
      "|  AUT| 1900|                6|               1.0|\n",
      "+-----+-----+-----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "medallistaXAnio2.groupBy(\"sigla\",\"annio\") \\\n",
    "    .agg(sum(\"count\").alias(\"Total de medallas\"), \\\n",
    "         avg(\"count\").alias(\"Medallas promedio\")) \\\n",
    "    .sort(col(\"annio\").asc(), col(\"Total de medallas\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones escalares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ejempo realizado para obtener las medallas ganadas por un pais se migará para poder visualizar como sería integrar SQL a un proceso de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 195:========>        (1 + 1) / 2][Stage 196:>                (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+\n",
      "|medalla|  equipo|sigla|\n",
      "+-------+--------+-----+\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Bronze|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "+-------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 196:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "resultadoDF.filter(resultadoDF.medalla != \"NA\") \\\n",
    "    .join(deportistaOlimpicoDF,deportistaOlimpicoDF.deportista_id == resultadoDF.deportista_id,\"left\") \\\n",
    "    .join(paisesDF,paisesDF.id == deportistaOlimpicoDF.equipo_id, \"left\") \\\n",
    "    .select(\"medalla\", \"equipo\",\"sigla\").sort( col(\"sigla\").desc() ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El uso de DF como SQL, se usa registrando un DF como tabla temportal.\n",
    "\n",
    "En el caso de realizar la conexión a una base de datos, este paso puede llegar a ser omitido. Ya que spark estará configurado para poder hacer las conexiones implicitamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadoDF.createOrReplaceTempView(\"resultado\")\n",
    "deportistaOlimpicoDF.createOrReplaceTempView(\"deportista\")\n",
    "paisesDF.createOrReplaceTempView(\"paises\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El alias asignado, será la forma en la cual sqlContext conocerá el DF internamente, ahora podemos hacer operaciones de forma tradicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|            1|           A Dijiang|     1|  24|   180|80.0|      199|\n",
      "|            2|            A Lamusi|     1|  23|   170|60.0|      199|\n",
      "|            3| Gunnar Nielsen Aaby|     1|  24|     0| 0.0|      273|\n",
      "|            4|Edgar Lindenau Aabye|     1|  34|     0| 0.0|      278|\n",
      "|            5|Christine Jacoba ...|     2|  21|   185|82.0|      705|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM deportista\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 208:>                                                        (0 + 2) / 2]\r",
      "\r",
      "[Stage 208:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+\n",
      "|medalla|  equipo|sigla|\n",
      "+-------+--------+-----+\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "| Bronze|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "| Silver|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "|   Gold|Zimbabwe|  ZIM|\n",
      "+-------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "                SELECT medalla, equipo, sigla FROM resultado r\n",
    "                JOIN deportista d\n",
    "                ON r.deportista_id = d.deportista_id\n",
    "                JOIN paises p\n",
    "                ON p.id = d.equipo_id\n",
    "                WHERE medalla <> \"NA\"\n",
    "                ORDER BY sigla DESC\n",
    "                \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF\n",
    "\n",
    "Nota: Este apartado en el curso se pone al final.\n",
    "\n",
    "Para ejemplificar la función creada por el usuario, cargamos deportistaError el cual tiene ausencia de valores.\n",
    "\n",
    "Con la UDF solucionamos el error. Esta no es una solución definitiva, solo es demostrativa para explicar como crear una UDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las **funciones definidas por el usuario o UDF**, por sus siglas en inglés, son una funcionalidad agregada en Spark para definir funciones basadas en columnas las cuales permiten extender las capacidades de Spark al momento de transformar el set de datos.\n",
    "\n",
    "Este tipo de implementaciones son convenientes cuando tenemos un desarrollo extenso donde hemos identificado la periodicidad de tareas repetitivas como suele ser en pasos de limpieza de datos, transformación o renombrado dinámico de columnas.\n",
    "\n",
    "Por lo anterior es común encontrar en un proyecto de Spark una librería independiente donde existen todas estas funciones agregadas para que los desarrolladores involucrados en el proyecto puedan usarlas a conveniencia.\n",
    "\n",
    "El uso de UDF no implica que las funciones que podemos crear nativamente con Python, Scala, R o Java no sean útiles. Una UDF tiene el objetivo de ofrecer un estándar interno en el proyecto que nos encontremos realizando. Además, en caso de ser necesario, una UDF puede ser modificada con ayuda de decoradores para que sea más extensible en diversos escenarios a los cuales nos podemos enfrentar.\n",
    "\n",
    "Otro motivo para usar UDF es que en el módulo de Spark MLlib, la librería nativa de Spark para operaciones de Machine Learning, las UDF juegan un papel vital al momento de hacer transformaciones. Por lo cual tener un uso familiar de estas ampliará considerablemente la curva de aprendizaje de Spark MLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deportista_id,nombre,genero,edad,altura,peso,equipo_id\r\n",
      "1,A Dijiang,1,24,180,80,199\r\n",
      "2,A Lamusi,1,23,170,60,199\r\n",
      "3,Gunnar Nielsen Aaby,1,24,,,273\r\n",
      "4,Edgar Lindenau Aabye,1,34,,,278\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 data/deportistaError.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoRDDerr =  spark.textFile(path+\"deportistaError.csv\").map(lambda line : line.split(\",\"))\n",
    "deportistaOlimpicoRDDerr = deportistaOlimpicoRDDerr.mapPartitionsWithIndex(dropFirstRow)\n",
    "\n",
    "deportistaOlimpicoRDDerr = deportistaOlimpicoRDDerr.map(lambda l : (\n",
    "    int(l[0]),l[1],l[2],l[3],l[4],l[5],l[6]\n",
    "))\n",
    "\n",
    "schema = StructType([\n",
    "StructField(\"deportista_id\",IntegerType(),False),\n",
    "StructField(\"nombre\",StringType(),False),\n",
    "StructField(\"genero\",StringType(),False),\n",
    "StructField(\"edad\",StringType(),True),\n",
    "StructField(\"altura\",StringType(),True),\n",
    "StructField(\"peso\",StringType(),True),\n",
    "StructField(\"equipo_id\",StringType(),True)     \n",
    "])\n",
    "\n",
    "deportistaError = sqlContext.createDataFrame(deportistaOlimpicoRDDerr,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|            1|           A Dijiang|     1|  24|   180|  80|      199|\n",
      "|            2|            A Lamusi|     1|  23|   170|  60|      199|\n",
      "|            3| Gunnar Nielsen Aaby|     1|  24|      |    |      273|\n",
      "|            4|Edgar Lindenau Aabye|     1|  34|      |    |      278|\n",
      "|            5|Christine Jacoba ...|     2|  21|   185|  82|      705|\n",
      "|            6|     Per Knut Aaland|     1|  31|   188|  75|     1096|\n",
      "|            7|        John Aalberg|     1|  31|   183|  72|     1096|\n",
      "|            8|\"Cornelia \"\"Cor\"\"...|     2|  18|   168|    |      705|\n",
      "|            9|    Antti Sami Aalto|     1|  26|   186|  96|      350|\n",
      "|           10|\"Einar Ferdinand ...|     1|  26|      |    |      350|\n",
      "|           11|  Jorma Ilmari Aalto|     1|  22|   182|76.5|      350|\n",
      "|           12|   Jyri Tapani Aalto|     1|  31|   172|  70|      350|\n",
      "|           13|  Minna Maarit Aalto|     2|  30|   159|55.5|      350|\n",
      "|           14|Pirjo Hannele Aal...|     2|  32|   171|  65|      350|\n",
      "|           15|Arvo Ossian Aaltonen|     1|  22|      |    |      350|\n",
      "|           16|Juhamatti Tapio A...|     1|  28|   184|  85|      350|\n",
      "|           17|Paavo Johannes Aa...|     1|  28|   175|  64|      350|\n",
      "|           18|Timo Antero Aaltonen|     1|  31|   189| 130|      350|\n",
      "|           19|Win Valdemar Aalt...|     1|  54|      |    |      350|\n",
      "|           20|  Kjetil Andr Aamodt|     1|  20|   176|  85|      742|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaError.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de UDF\n",
    "\n",
    "Los pasos para crear la udf son:\n",
    "\n",
    "1. Crear la función base\n",
    "2. Registrarla como udf\n",
    "3. Indicar al sqlContext que la usaremos como función nativa en sqlContext (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/16 23:24:06 WARN SimpleFunctionRegistry: The function ci_udf replaced a previously registered function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|deportista_id|altura|\n",
      "+-------------+------+\n",
      "|            1|   180|\n",
      "|            2|   170|\n",
      "|            3|  null|\n",
      "|            4|  null|\n",
      "|            5|   185|\n",
      "|            6|   188|\n",
      "|            7|   183|\n",
      "|            8|   168|\n",
      "|            9|   186|\n",
      "|           10|  null|\n",
      "|           11|   182|\n",
      "|           12|   172|\n",
      "|           13|   159|\n",
      "|           14|   171|\n",
      "|           15|  null|\n",
      "|           16|   184|\n",
      "|           17|   175|\n",
      "|           18|   189|\n",
      "|           19|  null|\n",
      "|           20|   176|\n",
      "+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 663, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    }
   ],
   "source": [
    "def ci(value: str) -> int:\n",
    "    return int(value) if len(value) > 0 else None\n",
    "\n",
    "\n",
    "ci_udf = udf(lambda z : ci(z), IntegerType())\n",
    "\n",
    "sqlContext.udf.register(\"ci_udf\", ci_udf)\n",
    "\n",
    "deportistaError.select(\"deportista_id\",ci_udf(\"altura\").alias(\"altura\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|            1|           A Dijiang|     1|  24|   180|  80|      199|\n",
      "|            2|            A Lamusi|     1|  23|   170|  60|      199|\n",
      "|            3| Gunnar Nielsen Aaby|     1|  24|      |    |      273|\n",
      "|            4|Edgar Lindenau Aabye|     1|  34|      |    |      278|\n",
      "|            5|Christine Jacoba ...|     2|  21|   185|  82|      705|\n",
      "|            6|     Per Knut Aaland|     1|  31|   188|  75|     1096|\n",
      "|            7|        John Aalberg|     1|  31|   183|  72|     1096|\n",
      "|            8|\"Cornelia \"\"Cor\"\"...|     2|  18|   168|    |      705|\n",
      "|            9|    Antti Sami Aalto|     1|  26|   186|  96|      350|\n",
      "|           10|\"Einar Ferdinand ...|     1|  26|      |    |      350|\n",
      "|           11|  Jorma Ilmari Aalto|     1|  22|   182|76.5|      350|\n",
      "|           12|   Jyri Tapani Aalto|     1|  31|   172|  70|      350|\n",
      "|           13|  Minna Maarit Aalto|     2|  30|   159|55.5|      350|\n",
      "|           14|Pirjo Hannele Aal...|     2|  32|   171|  65|      350|\n",
      "|           15|Arvo Ossian Aaltonen|     1|  22|      |    |      350|\n",
      "|           16|Juhamatti Tapio A...|     1|  28|   184|  85|      350|\n",
      "|           17|Paavo Johannes Aa...|     1|  28|   175|  64|      350|\n",
      "|           18|Timo Antero Aaltonen|     1|  31|   189| 130|      350|\n",
      "|           19|Win Valdemar Aalt...|     1|  54|      |    |      350|\n",
      "|           20|  Kjetil Andr Aamodt|     1|  20|   176|  85|      742|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deportistaError.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La persistencia de datos no ocurre por defecto en un DF o RDD de Spark, por lo cual debemos de indicar con el método 'cache', por otro lado, para poder verificar si esta almacenado o no, con el método 'is_cached' verificamos su estatus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ha descrito en clases pasadas, los RDD son la capa de abstracción primaria para poder interactuar con los datos que viven en nuestro ambiente de Spark. Aunque estos puedan ser enmascarados con un esquema dotándolos de las facultades propias de los DataFrames, la información de fondo sigue operando como RDD.\n",
    "\n",
    "Por lo tanto, la información, como indica el nombre de los RDD, se maneja de forma distribuida a lo largo del clúster, facilitando las operaciones que se van a ejecutar, ya que segmentos de información pueden encontrarse en diferentes ejecutores reduciendo el tiempo necesario para acceder a la información y poder así realizar los cálculos necesarios.\n",
    "\n",
    "Cuando un RDD o Dataframe es creado, según las especificaciones que se indiquen a la aplicación de Spark, creará un **esquema de particionado básico**, el cual distribuirá los datos a lo largo del clúster. Siendo así que al momento de ejecutar una acción, esta se ejecutará entre los diversos fragmentos de información que existan para poder así realizar de la forma más rápida las operaciones. Es por eso que un correcto esquema de particionado es clave para poder tener aplicaciones rápidas y precisas que además consuman pocos recursos de red.\n",
    "\n",
    "Otra de las tareas fundamentales es la **replicación de componentes y sus fragmentos**, ya que al aumentar la disponibilidad de estos podremos asegurar una tolerancia a fallos, mientras más se replique un valor es más probable que no se pierda si existe un fallo de red o energía, además de permitir una disponibilidad casi inmediata del archivo buscado.\n",
    "\n",
    "La partición y replicación son elementos que deben ser analizados según el tipo de negocio o requerimientos que se tengan en el desarrollo que se encuentre en progreso, por lo cual la cantidad de datos replicados o granularidad de datos existentes en los fragmentos dependerá en función de las reglas de negocio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/17 00:27:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , annio\n",
      " Schema: juego_id, annio\n",
      "Expected: juego_id but found: \n",
      "CSV file: file:///home/jovyan/work/data/juegos.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[558] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder verificar el tipo de almacenamiento asignado, debemos de conocer el valor de códigos que nos regresa getStorageLevel\n",
    "\n",
    "Para esto, podemos verificar en la documentación de spark:\n",
    "https://spark.apache.org/docs/2.4.6/api/python/_modules/pyspark/storagelevel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.getStorageLevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder cambiar el tipo de persistencia debemos de primero retirarla y posterior a eso asignarle la que deseamos.\n",
    "\n",
    "Con el método persist, asignaremos la persistencia que nosotros deseamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[558] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[558] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.persist(StorageLevel.MEMORY_AND_DISK_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(True, True, False, False, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(True, True, False, False, 2)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.getStorageLevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos crear nuestros propios esquemas de persistencia según las reglas y restricciones de negocio que tengamos en el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def __init__(self, useDisk, useMemory, useOffHeap, deserialized, replication=1):\n",
    "StorageLevel.MEMORY_AND_DISK_3 = StorageLevel(True,True,False,False,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[558] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medallistaXAnio.rdd.unpersist()\n",
    "medallistaXAnio.rdd.persist(StorageLevel.MEMORY_AND_DISK_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
