{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a href=\"http://cocl.us/pytorch_link_top\">\n    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n</a> "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h1>Linear  Classifier with PyTorch </h1>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<p>Before you use a  Deep neural network to solve the classification problem,  it 's a good idea to try and solve the problem with the simplest method. You will need the dataset object from the previous section.\nIn this lab, we solve the problem with a linear classifier.\n You will be asked to determine the maximum accuracy your linear classifier can achieve on the validation data for 5 epochs. We will give some free parameter values if you follow the instructions you will be able to answer the quiz. Just like the other labs there are several steps, but in this lab you will only be quizzed on the final result. </p>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h2>Table of Contents</h2>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n\n\n<ul>\n    <li><a href=\"#download_data\"> Download data</a></li>\n    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n    <li><a href=\"#data_class\"> Dataset Class</a></li>\n    <li><a href=\"#trasform_Data_object\">Transform Object and Dataset Object</a></li>\n    <li><a href=\"#Question\">Question</a></li>\n</ul>\n<p>Estimated Time Needed: <strong>25 min</strong></p>\n </div>\n<hr>\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h2 id=\"download_data\">Download Data</h2>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "In this section, you are going to download the data from IBM object storage using <b>wget</b>, then unzip them.  <b>wget</b> is a command the retrieves content from web servers, in this case its a zip file. Locally we store the data in the directory  <b>/resources/data</b> . The <b>-p</b> creates the entire directory tree up to the given directory."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "First, we download the file that contains the images, if you dint do this in your first lab uncomment:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip -P /resources/data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We then unzip the file, this ma take a while:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#!unzip -q  /resources/data/concrete_crack_images_for_classification.zip -d  /resources/data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We then download the files that contain the negative images:"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The following are the libraries we are going to use for this lab:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim \nimport numpy as np",
            "execution_count": 107,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h2 id=\"data_class\">Dataset Class</h2>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "In this section, we will use the previous code to build a dataset class. As before, make sure the even samples are positive, and the odd samples are negative.  If the parameter <code>train</code> is set to <code>True</code>, use the first 30 000  samples as training data; otherwise, the remaining samples will be used as validation data. Do not forget to sort your files so they are in the same order.  "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "class Dataset(Dataset):\n\n    # Constructor\n    def __init__(self,transform=None,train=True):\n        directory=\"\"  #/resources/data\n        positive=\"Positive\"\n        negative=\"Negative\"\n\n        positive_file_path=os.path.join(directory,positive)\n        negative_file_path=os.path.join(directory,negative)\n        positive_files=[os.path.join(positive_file_path,file) for file in  os.listdir(positive_file_path) if file.endswith(\".jpg\")]\n        positive_files.sort()\n        negative_files=[os.path.join(negative_file_path,file) for file in  os.listdir(negative_file_path) if file.endswith(\".jpg\")]\n        negative_files.sort()\n        number_of_samples=len(positive_files)+len(negative_files)\n        self.all_files=[None]*number_of_samples\n        self.all_files[::2]=positive_files\n        self.all_files[1::2]=negative_files \n        # The transform is goint to be used on image\n        self.transform = transform\n        #torch.LongTensor\n        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n        self.Y[::2]=1\n        self.Y[1::2]=0\n        \n        if train:\n            self.all_files=self.all_files[0:30000]\n            self.Y=self.Y[0:30000]\n            self.len=len(self.all_files)\n        else:\n            self.all_files=self.all_files[30000:]\n            self.Y=self.Y[30000:]\n            self.len=len(self.all_files)    \n       \n    # Get the length\n    def __len__(self):\n        return self.len\n    \n    # Getter\n    def __getitem__(self, idx):\n        \n        \n        image=Image.open(self.all_files[idx])\n        y=self.Y[idx]\n          \n        \n        # If there is any transform method, apply it onto the image\n        if self.transform:\n            image = self.transform(image)\n\n        return image, y",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h2 id=\"trasform_Data_object\">Transform Object and Dataset Object</h2>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a transform object, that uses the <code>Compose</code> function. First use the transform <code>ToTensor()</code> and followed by <code>Normalize(mean, std)</code>. The value for <code> mean</code> and <code>std</code> are provided for you."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "mean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n# transforms.ToTensor()\n#transforms.Normalize(mean, std)\n#transforms.Compose([])\n\ntransform =transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
            "execution_count": 3,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create object for the training data  <code>dataset_train</code> and validation <code>dataset_val</code>. Use the transform object to convert the images to tensors using the transform object:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dataset_train=Dataset(transform=transform,train=True)\ndataset_val=Dataset(transform=transform,train=False)",
            "execution_count": 7,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dataset_train[20001][1]",
            "execution_count": 83,
            "outputs": [
                {
                    "data": {
                        "text/plain": "tensor(0)"
                    },
                    "execution_count": 83,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We  can find the shape of the image:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dataset_train[0][0].shape",
            "execution_count": 8,
            "outputs": [
                {
                    "data": {
                        "text/plain": "torch.Size([3, 227, 227])"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We see that it's a color image with three channels:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "size_of_image=3*227*227\nsize_of_image",
            "execution_count": 9,
            "outputs": [
                {
                    "data": {
                        "text/plain": "154587"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h2 id=\"Question\"> Question <h2>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<b> Create a custom module for Softmax for two classes,called model. The input size should be the <code>size_of_image</code>, you should record the maximum accuracy achieved on the validation data for the different epochs. For example if the 5 epochs the accuracy was 0.5, 0.2, 0.64,0.77, 0.66 you would select 0.77.</b>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Train the model with the following free parameter values:"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<b>Parameter Values</b>\n   <li>learning rate:0.1 </li>\n   <li>momentum term:0.1 </li>\n   <li>batch size training:1000</li>\n   <li>Loss function:Cross Entropy Loss </li>\n   <li>epochs:5</li>\n   <li>set: torch.manual_seed(0)</li>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "torch.manual_seed(0)",
            "execution_count": 10,
            "outputs": [
                {
                    "data": {
                        "text/plain": "<torch._C.Generator at 0x7fd3f6197410>"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<b>Custom Module:</b>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Create dataset object\n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, Layers):\n        super(Net, self).__init__()\n        self.hidden = nn.ModuleList()\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            self.hidden.append(nn.Linear(input_size, output_size))\n    \n    # Prediction\n    def forward(self, activation):\n        L = len(self.hidden)\n        for (l, linear_transform) in zip(range(L), self.hidden):\n            if l < L - 1:\n                activation = F.relu(linear_transform(activation))    \n            else:\n                activation = linear_transform(activation)\n        return activation\n    ",
            "execution_count": 28,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<b>Model Object:</b>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# size_of_image = 154587\nLayers = [size_of_image, 2]\nmodel = Net(Layers)\nmodel",
            "execution_count": 113,
            "outputs": [
                {
                    "data": {
                        "text/plain": "Net(\n  (hidden): ModuleList(\n    (0): Linear(in_features=154587, out_features=2, bias=True)\n  )\n)"
                    },
                    "execution_count": 113,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<b>Optimizer:</b>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Define the learning rate, optimizer, criterion and data loader\n\nlearning_rate = 0.1\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.1)",
            "execution_count": 114,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<b>Criterion:</b>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "criterion = nn.CrossEntropyLoss()",
            "execution_count": 115,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<b>Data Loader Training and Validation:</b>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=1000)\nvalidation_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=1000)  \ntrain_loader",
            "execution_count": 116,
            "outputs": [
                {
                    "data": {
                        "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x7fd3ece7d710>"
                    },
                    "execution_count": 116,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<b>Train Model with 5 epochs, should take 35 minutes: </b>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Define a function for calculating accuracy\n\ndef accuracy(model, data_set):\n    ztrain = model(np.asarray(data_set.all_files).view(-1, 3*227*227 ))\n    _, yhat = torch.max(ztrain.data, 1)\n    return (yhat == data_set.Y).numpy().mean()",
            "execution_count": 117,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "Results = {\"momentum 0\": {\"Loss\": 0, \"Accuracy:\": 0}, \"momentum 0.1\": {\"Loss\": 0, \"Accuracy:\": 0}}",
            "execution_count": 118,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Define the function for training the model\nloss_list = []\naccuracy_list = []\nN_test = len(dataset_val)\n\ndef train(dataset_train, model, criterion, train_loader, validation_loader, optimizer, epochs=10):\n    LOSS = []\n    ACC = []\n    \n    for epoch in range(epochs):\n        for x, y in train_loader:\n            optimizer.zero_grad()\n            yhat = model(x.view(-1, 3*227*227))\n            loss = criterion(yhat, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        LOSS.append(loss.item())\n        #ACC.append(accuracy(model,dataset_train))  #data_set\n            \n        correct = 0\n        # perform a prediction on the validationdata  \n        for x_test, y_test in validation_loader:\n            z = model(x_test.view(-1, 3*227*227 ))\n            _, yhat = torch.max(z.data, 1)\n            correct += (yhat == y_test).sum().item()  \n        accuracyTest = correct / N_test\n        loss_list.append(loss.data)\n        accuracy_list.append(accuracyTest)\n        \n        \n    results ={\"Loss\":LOSS, \"Accuracy\":ACC}\n    fig, ax1 = plt.subplots()\n    color = 'tab:red'\n    ax1.plot(LOSS,color=color)\n    ax1.set_xlabel('epoch', color=color)\n    ax1.set_ylabel('total loss', color=color)\n    ax1.tick_params(axis = 'y', color=color)\n    \n    ax2 = ax1.twinx()  \n    color = 'tab:blue'\n    ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1\n    ax2.plot(accuracy_list, color=color)\n    ax2.tick_params(axis='y', color=color)\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    \n    plt.show()\n    return results",
            "execution_count": 123,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "Results[\"momentum 0\"] = train(dataset_train, model, criterion, train_loader,validation_loader, optimizer, epochs=5)",
            "execution_count": 124,
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 2 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h2>About the Authors:</h2>\n <a href=\\\"https://www.linkedin.com/in/joseph-s-50398b136/\\\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Copyright &copy; 2019 <a href=\"cognitiveclass.ai\"> cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}